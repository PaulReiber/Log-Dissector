#!/usr/bin/awk -f
####################################################################
# LogDissector - a format-independent logfile analysis tool.
#
# Author:  Paul Reiber - reiber at gmail dot com
# URL: http://reiber.org/Code/logDissector
####################################################################
# PLATFORMS:
#     should work on most Linux implementations - mawk compatible
#
# USAGE EXAMPLES:
#     awk -v skip="1,3,5" -v collect="2,4,6" -f logdissector.awk any.logfile
#     tail -1000000 /var/log/messages | awk -f logdissector.awk
#

# if you encounter problems it may be related to how your awk understands FS
# BEGIN { FS="\t\]\[| " } # fields are separated by space tab pipe open-bracket or close-bracket
BEGIN { print "FS=[" FS "]" } # fields are separated by space tab pipe open-bracket or close-bracket

# for every input line...
 { line=""; for( word=1; word<=NF; word=word+1){ # initialize line and loop over all fields setting "word" to the field number
                #print "in[" word "]=" $(word)
                if      ("," $(word) "," !~ /^,,$/)                     { words[$(word)]++; } # all non-null word gets counted
                if      (index("," skip    "," , "," word ",")>0)       { line=line " <skipped-field>" } # honor skip on commandline
                else if (index("," collect "," , "," word ",")>0)       { line=line " <collected-field>"; collection[$(word)]++ } # honor collect too
                else if ("," $(word) "," ~ /^,,$/)                      { line=line " <empty>" } # empty fields (happens because of our FS)
                else if ($(word) ~ /^[0-9]?[0-9]:[0-9][0-9](:[0-9][0-9])?$/)
                                                                        { line=line " <time>" } # time formats - NN:NN or NN:NN:NN
                else if ($(word) ~ /^([Jj]an(uary)?|[Ff]eb(ruary)?|[Mm]ar(ch)?|[Aa]pr(il)?|[Mm]ay|[Jj]un(e)?|[Jj]ul(y)?|[Aa]ug(ust)?|[Ss]ep(t|tember)?|[Oo]ct(ober)?|[Nn]ov(ember)?|[Dd]ec(ember)?)$/)
                                                                        { line=line " <month>" } # months and abbreviated months
                else if ($(word) ~ /^[0-9][0-9]\/([Jj]an(uary)?|[Ff]eb(ruary)?|[Mm]ar(ch)?|[Aa]pr(il)?|[Mm]ay|[Jj]un(e)?|[Jj]ul(y)?|[Aa]ug(ust)?|[Ss]ep(t|tember)?|[Oo]ct(ober)?|[Nn]ov(ember)?|[Dd]ec(ember)?)\/[0-9:]+$/)
                                                                        { line=line " <datetimestamp>";     dates[$(word)]++ } # date-and-time-stamps
                else if ($(word) ~ /[0-9][0-9][0-9][0-9]-[0-9][0-9]-[0-9][0-9]T[0-9][0-9]:[0-9][0-9]:[0-9][0-9][.][0-9][0-9][0-9]/)
                                                                        { line=line " <datetimestamp>";     dates[$(word)]++ } # rubrik style dates
                else if ($(word) ~ /^([Mm]on(day)?|[Tt]ue(s|sday)?|[Ww]ed(s|nesday)?|[Tt]hu(r|rs|rsday)?|[Ff]ri(day)?|[Ss]at(urday)?|[Ss]un(day)?)$/)
                                                                        { line=line " <weekday>" } # weekdays and abbreviated weekdays
                else if ($(word) ~ /^[+]?[0-9.,]+$/)                    { line=line " <number-or-ip>";      numbers[$(word)]++ } # numbers
                else if ($(word) ~ /^\([+]?[0-9.,]+$/)                  { line=line " (<number-or-ip>"; gsub("[^0-9.]","",$(word));  numbers[$(word)]++ } # numbers
                else if ($(word) ~ /^[+]?[0-9.,]+\)$/)                  { line=line " <number-or-ip>)"; gsub("[^0-9.]","",$(word));  numbers[$(word)]++ } # numbers
                else if ($(word) ~ /^HTTP\/.*$/)                        { line=line " " $(word); } # guard so this doesnt match paths
                else if ($(word) ~ /^\/?([^\/]+\/[^\/]+)*\/?$/)         { line=line " <path>";              paths[$(word)]++ } # paths
                else if ($(word) ~ /^\/[^\/]+(\/[^\/]+)*\/?$/)          { line=line " <path>";              paths[$(word)]++ } # paths
                else if ($(word) ~ /^[0-9\/]+(,)?$/)                    { line=line " <date-or-fraction>";  dates[$(word)]++ } # dates
                else if ($(word) ~ /^http(s)?:\/\//)                    { line=line " <url>";               urls[$(word)]++ } # urls
                else if ($(word) ~ /^.+\.[a-zA-Z][a-zA-Z][a-zA-Z]\.?$/) { line=line " <file-or-host-name>"; names[$(word)]++ } # names
                else if ($(word) ~ /RVMHM[0-9]+S[0-9]+/)                { line=line " <nodename>";          nodes[$(word)]++ } # rubrik nodenames
                else if ($(word) ~ /[A-Z_]+[-0-9a-f]+:::[0-9]+/)        { line=line " <job-id>";            jobs[$(word)]++ } # rubrik job IDs
                else if ($(word) ~ /^.*\[[0-9.]+\].*$/)                 { gsub("\[[0-9.]+\]", "[<n>]", $(word)); line=line " " $(word); arrays[$(word)]++ } # numericarrays
                else                                                    { line=line " " $(word) } # append unrecognized words to the pattern
        }
        patterns[line]++; printf("."); # bump the count of lines matching the pattern "line", and print a dot for a progress meter.
}

END {   # after all input lines have been handled...
        print " done."; print "Parsed " NR " lines; please review the results in these files:"
        # people say associative arrays cant be sorted in awk - but they can if you pipe to a sort subprocess!
        for(j in patterns)   { print patterns[j],j   | "sort -rn > patterns"};   close("sort -rn > patterns");
        for(j in collection) { print collection[j],j | "sort -rn > collected"};  close("sort -rn > collected");
        for(j in numbers)    { print numbers[j],j    | "sort -rn > numbers"};    close("sort -rn > numbers");
        for(j in dates)      { print dates[j],j      | "sort -rn > dates"};      close("sort -rn > dates");
        for(j in names)      { print names[j],j      | "sort -rn > names"};      close("sort -rn > names");
        for(j in paths)      { print paths[j],j      | "sort -rn > paths"};      close("sort -rn > paths");
        for(j in urls)       { print urls[j],j       | "sort -rn > urls"};       close("sort -rn > urls");
        for(j in words)      { print words[j],j      | "sort -rn > words"};      close("sort -rn > words");
        for(j in arrays)     { print arrays[j],j     | "sort -rn > arrays"};     close("sort -rn > arrays");
        for(j in nodes)      { print nodes[j],j      | "sort -rn > nodes"};      close("sort -rn > nodes");
        for(j in jobs)       { print jobs[j],j       | "sort -rn > jobs"};       close("sort -rn > jobs");
        system("ls -l *");
}

#
# rubrik notes
#
# removed code that added an extension to the output filenames as the mac version of awk cant deal with it
#
# added...
# - new datestamp format to handle how CDM dates - added to existing dates collection
# - new collections for nodes and jobs
#
# note that most regex are bounded with ^ and $ for begin and end of word.
# however the regex for nodenames and jobIDs is not, so they will match any word which has them within it.
#
# also this only has one of the nodename formats, there are a few, they should be added.
#
